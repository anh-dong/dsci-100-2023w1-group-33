{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ec870a-380e-4d7c-ae81-f7aae633d72a",
   "metadata": {},
   "source": [
    "# Exploring the Relationship Between the Meta Scores of Films and the Reviews of the General Audiance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d90c53-59c7-46f8-ace1-38820a80375f",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "IMDB is an online database for films, television series, podcasts, and other media. This project will be working with movie data from IMDB. The data set of interest contains content data - including cast, production crew, plot summary, and scores. IMDB presents two kinds of scores; IMDB scores which are user-generated averages of reviews submitted to IMDB by the general audience, and Meta Scores which are critic-generated, representing the views of professionals who analyze films.\n",
    "\n",
    "The goal of this project is to answer the following question:\n",
    "\"How accurate are the Meta Scores of films in predicting the reception of the general audience?\"\n",
    "\n",
    "\n",
    "The data set is from Kaggle, and includes data from the top 1000 movies based on the IMDB score. The data set includes the following columns:\n",
    "* Series_Title: the name of the film\n",
    "* Released_year: year it was released\n",
    "* Certificate: certificate earned by the movie\n",
    "* Runtime - total runtime\n",
    "* Genre - list of genres the film falls into\n",
    "* IMDB_Rating - the IMDB rating given by IMDB user reviews\n",
    "* Overview - plot summary\n",
    "* Meta_score - meta score of the movie determined by movie critics\n",
    "* Director - name of the director of the movie\n",
    "* Star1, Star2, Star3, Star4 - names of the stars of the movie in order of significance\n",
    "* No_of_votes - number of reviews on IMDB\n",
    "* Gross - how much money the movie earned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47093674-25bb-4f5d-8c96-d8f59c4e9d25",
   "metadata": {},
   "source": [
    "Dataset Origin: https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5856bb-1f09-47ee-a423-0eae434b800e",
   "metadata": {},
   "source": [
    "#### 1. Import Libraries\n",
    "Tidyverse, dplyr, and tidymodels libraries were imported for data manipulation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8653314-ca0b-4c82-82ad-37717519f20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49812b76-0ef9-4609-bb4f-2919110f36d3",
   "metadata": {},
   "source": [
    "#### 2. Reading Data from Github\n",
    "The data was downloaded from: https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows\n",
    "then added to this project's repository. The following cell reads the data from the repository as a CSV file and filters for films released after 1970, as these films will represent modern conditions better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92eecd-87c5-401a-8934-8651348acf39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url <- \"https://github.com/anh-dong/dsci-100-2023w1-group-33/blob/main/data/imdb_top_1000.csv?raw=true\"\n",
    "movies <- read_csv(url) |>\n",
    "    filter(Released_Year > 1970) |>\n",
    "    select(IMDB_Rating, Meta_score) |>\n",
    "    na.omit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee19691-ed5c-4b5b-a64a-80f30a38a847",
   "metadata": {},
   "source": [
    "#### 3. Create a training data set\n",
    "The raw data is then split into a training and testing set of 75% and 25% of the raw data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d2c8c-c110-4d64-a466-0c340f96b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "\n",
    "movies_split <- initial_split(movies, prop = 0.75, strata = Meta_score)\n",
    "movies_training <- training(movies_split)\n",
    "movies_testing <- testing(movies_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7009714-8ac8-4107-aefb-4ff86356e872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdf0ce62-f647-4de5-ac4b-d4e0dc3fad79",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A plot of IMDB_Rating vs Meta_score was created using ggplot and geom_point. Since there was significant overlap between many data points, an alpha of 0.2 was used to visualize all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e05696-d425-42d5-a3ff-795af12436fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.height = 8, repr.plot.width = 7)\n",
    "\n",
    "movies_eda <- movies_training |>\n",
    "    ggplot(aes(x = Meta_score, y = IMDB_Rating)) +\n",
    "        geom_point(alpha = 0.2) +\n",
    "        xlab(\"Meta Score\") +\n",
    "        ylab(\"IMDB Rating\") +\n",
    "        ggtitle(\"IMDB Rating vs Meta Score\")+\n",
    "theme(text = element_text(size = 20))\n",
    "movies_eda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f87546-c67b-4192-860b-debec22804ce",
   "metadata": {},
   "source": [
    "To best determine the relationship between the IMDB Rating and the Meta Score a linear regression was performed using Meta_score as the predictor and IMDB Rating as the response variable. The training data was fit to this workflow to predict parameters for the y-intercept and slope of the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3be12-7e53-4c42-bea5-bf0bdd625eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_spec <- linear_reg() |>\n",
    "  set_engine(\"lm\") |>\n",
    "  set_mode(\"regression\")\n",
    "\n",
    "# TODO: Swap variables\n",
    "lm_recipe <- recipe(IMDB_Rating ~ Meta_score, data = movies_training)\n",
    "\n",
    "lm_fit <- workflow() |>\n",
    "  add_recipe(lm_recipe) |>\n",
    "  add_model(lm_spec) |>\n",
    "  fit(data = movies_training)\n",
    "lm_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a970f-d553-4d46-a6a3-77ee07e2a8df",
   "metadata": {},
   "source": [
    "The linear regression line was then plotted against the training data to visualize how well it fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec19b0-5e61-4cde-9b2b-dffc3b299fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_preds <- lm_fit |>\n",
    "   predict(movies_training) |>\n",
    "   bind_cols(movies_training)\n",
    "\n",
    "lm_predictions <- movies_preds |>\n",
    "    ggplot(aes(x = Meta_score, y = IMDB_Rating)) +\n",
    "        geom_point(alpha = 0.4) +\n",
    "        geom_line(\n",
    "            mapping = aes(x = Meta_score, y = .pred), \n",
    "            color = \"blue\") +\n",
    "            labs(x=\"Meta Score\", y=\"IMDB Rating Score\", title=\"Meta Score vs. IMDB Rating Score\", caption=\"Training data set\")+\n",
    "        theme(text = element_text(size = 20))\n",
    "lm_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656029d-5b43-4262-a744-772ac8d07542",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90b1f2-cdf1-4446-80fa-940d39a83405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_training_results <- lm_fit |>\n",
    "         predict(movies_training) |>\n",
    "         bind_cols(movies_training) |>\n",
    "         metrics(truth = IMDB_Rating, estimate = .pred)\n",
    "\n",
    "lm_rmse <- lm_training_results |>\n",
    "          filter(.metric == \"rmse\") |>\n",
    "          select(.estimate) |>\n",
    "          pull()\n",
    "\n",
    "lm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e779458-66a2-4512-ab0f-f88a8bfd22d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: We should calculate this, it will help us determine how good our prediction is.\n",
    "lm_test_results <- lm_fit |>\n",
    "         predict(movies_testing) |>\n",
    "         bind_cols(movies_testing) |>\n",
    "         metrics(truth = IMDB_Rating, estimate = .pred)\n",
    "\n",
    "lm_rmspe <- lm_test_results |>\n",
    "          filter(.metric == \"rmse\") |>\n",
    "          select(.estimate) |>\n",
    "          pull()\n",
    "\n",
    "\n",
    "lm_rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a337f-7b52-4a72-9bf7-815a8a3f2f3a",
   "metadata": {},
   "source": [
    "The testing data set was then compared to their predictions based on our model and plotted against the line of best fit calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43032b96-8768-4247-9632-7336fcb1e8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds <-  lm_fit |>\n",
    "   predict(movies_testing) |>\n",
    "   bind_cols(movies_testing)\n",
    "\n",
    "lm_predictions_test <- test_preds |>\n",
    "     ggplot(aes(x = Meta_score, y =IMDB_Rating )) +\n",
    "         geom_point(alpha = 0.4) +\n",
    "         geom_line(\n",
    "             mapping = aes(x = Meta_score, y = .pred), \n",
    "             color = \"blue\") +\n",
    "        labs(x=\"Meta Score\", y=\"IMDB Rating Score\", title=\"Meta Score vs. IMDB Rating Score\", caption=\"Testing data set\")+\n",
    "         theme(text = element_text(size = 20))\n",
    "lm_predictions_test\n",
    "#TODO: in general we should try and get rid of the warning messages. I think this should be done when we remove NA values from our training/testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0788ec-c559-4596-a0d9-08f5d4fe41c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Expected Outcomes and Significance:\n",
    "\n",
    "As we can see our $RMSE$ when assessing model goodness of fit on the training data is quite low and our $RMSPE$ when assessing model prediction quality on a test data set is also low. This means that our linear regression line fits the data well and that our predictions are accurate. \n",
    "\n",
    "This is expected that the Meta Scores and IMDb Rating will have a weak positive relationship. Critics are trying to give audiences an accurate expectation on the film based on their ratings so both scoring/rating systems should correlate positively with each other. However, critics and general audiences often look for different things in their ratings, producing more variability between the two ratings, potentially causing a weaker relationship. This relationship will allow audiences to understand how a meta score should factor into their decision to see a movie before any general audience ratings are available.\n",
    "\n",
    "As we mentioned in the introduction, IMDb is great for seeing what general audiences think of a movie. If you don't care what the critics say and want to see what people like yourself thought of a film, then you should use IMDb. We must, however, be aware that fans often skew the vote with 10-star ratings or 1-star ratings, which makes the score vary significantly. Next time you are trying to decide whether a film is worth watching, we would suggest using both IMDb and Meta Score as one focuses on user reviews while the other is a weighted average of reviews from top critics and publications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48f1eb9-70a1-4ba5-87ea-19d52f12e8bc",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "How Meta Scores are computed:\n",
    "\n",
    "How do you compute metascores? – metacritic support. Metacritic Support. (2023, October). https://metacritichelp.zendesk.com/hc/en-us/articles/14478499933079-How-do-you-compute-METASCORES-\n",
    "\n",
    "Factors that influence Meta Scores (critics):\n",
    "\n",
    "Gruber, M. (2022, April 20). How critics produce a film analysis. Ready Steady Cut. https://readysteadycut.com/2022/04/20/how-critics-produce-a-film-analysis/\n",
    "\n",
    "Factors that effect IMDB score (a report):\n",
    "\n",
    "Türker, B. (2021, August 17). Eda project - what are the factors affecting IMDB ratings?. Medium. https://medium.com/i%CC%87stanbuldatascienceacademy/eda-project-what-are-the-factors-affecting-imdb-ratings-e91f41396c89\n",
    "\n",
    "Inconsistency in how movie critics and general viewers judge films:\n",
    "\n",
    "Collazo, M. (2014, April 30). How movie critics and moviegoers view films differently. The Artifice. https://the-artifice.com/movie-critics-and-moviegoers-view-films-differently/\n",
    "\n",
    "Data Set Origin:\n",
    "\n",
    "Shankhdhar, H. (2021, February 1). IMDB movies dataset. Kaggle. https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
