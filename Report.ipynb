{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ec870a-380e-4d7c-ae81-f7aae633d72a",
   "metadata": {},
   "source": [
    "# Exploring the Relationship Between the Meta Scores of Films and the Reviews of the General Audiance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d90c53-59c7-46f8-ace1-38820a80375f",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "IMDb is an online database for films, television series, podcasts, and other media. This project will be working with movie data from IMDb that contains data on the cast, production crew, plot summary, and scores.$^1$ This data set presents two kinds of quantitative ratings IMDb scores which are averages of user-generating ratings out of 10,$^2$ and Meta Scores which are weighted averages of critic-generated reviews out of 100.$^3$\n",
    "\n",
    "Though each professional critic has their own set of goals and writing style, in general, there are many components that all critics consider when reviewing films. Critics tend to watch films with little to no information to avoid preconceived judgment and allow for an unbiased background. While watching a film, critics will often re-watch the film to ensure they catch all details of the film. When compiling a review, a critic will often focus on certain elements to create their review. These elements include Plot, Theme, Acting/Characterization, Direction, Music, Cinematography, Production Design, Special Effects, Editing, and Dialogue.$^4$\n",
    "\n",
    "Unlike Meta Scores, IMDb scores are computed as unweighted averages of general audience reviews, with an average of 7. The \"critics\" behind the IMDb scores don't all review films based on a specific set list of elements. There are possible external factors that can influence these reviews such as the opinions of others and marketing of the film, these factors can produce a preconceived judgment before they can produce their own opinions. General audience members tend to watch films with some level of distraction and generally don't watch for the sake of critiquing the same factors as critics. So the reviews that affect the IMDb scores of a film can be biased and affected by the feelings of the individual reviewer and external factors.\n",
    "\n",
    "The main difference between IMDb scores and Meta Scores is that IMDb scores are computed from potentially biased reviews of the general audience, whereas Meta Scores are computed from less biased critic reviews that evaluate films based on a standardized formula. Unbiased opinions are typically the best representation of quality, however they might not represent how entertaining they might be for a general audience because they focus on different aspects.$^5$ Though each individual review behind the IMDb scores is subject to the bias of the reviewer, for this project it is assumed that the pool of reviews used to formulate the IMDb score is a good representation of the general audience.\n",
    "\n",
    "The goal of this project is to answer the following question: \"How accurate are the Meta Scores of films in predicting the reception of the general audience?\"\n",
    "\n",
    "The data set is from Kaggle and includes data from the top 1000 movies based on the IMDb score. The data set includes the following columns:\n",
    "\n",
    "* Series_Title: the name of the film\n",
    "* Released_year: year it was released\n",
    "* Certificate: certificate earned by the movie\n",
    "* Runtime: total runtime in minutes\n",
    "* Genre: list of genres the film falls into\n",
    "* IMDB_Rating: the average IMDB rating given by IMDB user reviews out of 10\n",
    "* Overview: plot summary\n",
    "* Meta_score: meta score of the movie determined by movie critics out of 100\n",
    "* Director: name of the director of the movie\n",
    "* Star1, Star2, Star3, Star4: names of the stars of the movie in order of significance\n",
    "* No_of_votes: number of reviews on IMDB\n",
    "* Gross: how much money the movie earned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5856bb-1f09-47ee-a423-0eae434b800e",
   "metadata": {},
   "source": [
    "## Methods:\n",
    "#### 1. Import Libraries\n",
    "Tidyverse, dplyr, and tidymodels libraries were imported for data manipulation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8653314-ca0b-4c82-82ad-37717519f20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49812b76-0ef9-4609-bb4f-2919110f36d3",
   "metadata": {},
   "source": [
    "#### 2. Read data from repository\n",
    "The data was downloaded from Kaggle$^1$ then added to this project's repository. The following cell reads the data from the repository as a CSV file and filters for films released after 1970, as these films will represent modern conditions better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92eecd-87c5-401a-8934-8651348acf39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url <- \"https://github.com/anh-dong/dsci-100-2023w1-group-33/blob/main/data/imdb_top_1000.csv?raw=true\"\n",
    "movies <- read_csv(url) |>\n",
    "    filter(Released_Year > 1970) |>\n",
    "    select(IMDB_Rating, Meta_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee19691-ed5c-4b5b-a64a-80f30a38a847",
   "metadata": {},
   "source": [
    "#### 3. Create Training Data\n",
    "The raw data is then split into a training and testing set of 75% and 25% of the raw data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d2c8c-c110-4d64-a466-0c340f96b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "\n",
    "movies_split <- initial_split(movies, prop = 0.75, strata = Meta_score)\n",
    "movies_training <- training(movies_split)\n",
    "movies_testing <- testing(movies_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf0ce62-f647-4de5-ac4b-d4e0dc3fad79",
   "metadata": {},
   "source": [
    "#### 4. Summary Table\n",
    "The training data was summarized by first normalizing and counting each normalized value for Meta_score and IMDB_Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7009714-8ac8-4107-aefb-4ff86356e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_summary <- movies_training |>\n",
    "    mutate(Meta_score = round(scale(Meta_score), 0), IMDB_Rating = round(scale(IMDB_Rating), 0))\n",
    "\n",
    "movies_table_Meta_scores <- movies_summary |>\n",
    "    group_by(Meta_score) |>\n",
    "    summarize(Meta_score_count = n()) |>\n",
    "    rename(normalized_value = Meta_score)\n",
    "\n",
    "movies_table_IMDB_Rating <- movies_summary |>\n",
    "    group_by(IMDB_Rating) |>\n",
    "    summarize(IMDB_Rating_count = n()) |>\n",
    "    rename(normalized_value = IMDB_Rating)\n",
    "\n",
    "joined <- left_join(movies_table_Meta_scores, movies_table_IMDB_Rating) |>\n",
    "    mutate(IMDB_Rating_count = replace(IMDB_Rating_count, is.na(IMDB_Rating_count), 0))\n",
    "joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca8e8b-41c9-47fe-b613-9c639a69b03a",
   "metadata": {},
   "source": [
    "##### Table 1:\n",
    "Counts of normalized values for Meta_score and IMDB_Rating for the training data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f1f57-87e7-4ef7-90f0-e53c4517928c",
   "metadata": {},
   "source": [
    "#### 5. Summary Visuals\n",
    "NA values were first removed then the distribution of the normalized data was then visualized by plotting them on a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c2905-0ef5-4bdf-8b06-c3e0b725be96",
   "metadata": {},
   "source": [
    "movies_summary <- na.omit(movies_summary)\n",
    "\n",
    "Meta_score_hist <- movies_summary |>\n",
    "    ggplot(aes(Meta_score)) +\n",
    "        geom_histogram(binwidth = 1) +\n",
    "        xlab(\"Normalized Meta Score\") +\n",
    "        ylab(\"Count\") +\n",
    "        ggtitle(\"Distribution of Normalized Meta Scores\")\n",
    "Meta_score_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa6e19-d18f-4721-8270-68ee4e28383f",
   "metadata": {},
   "source": [
    "##### Figure 1:\n",
    "Histogram of normalized IMDB Ratings using geom_histogram with a binwidth of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc5cd3-d9e6-4f91-b391-7a98d1d7c59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "IMDB_Review_hist <- movies_summary |>\n",
    "    ggplot(aes(IMDB_Rating)) +\n",
    "        geom_histogram(binwidth = 1) +\n",
    "        xlab(\"Normalized IMDB Rating\") +\n",
    "        ylab(\"Count\") +\n",
    "        ggtitle(\"Distribution of Normalized IMDB Ratings\")\n",
    "        \n",
    "IMDB_Review_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0a5e9-62df-4f5f-92b1-1e29416b83f4",
   "metadata": {},
   "source": [
    "##### Figure 2: \n",
    "Histogram of normalized IMDB Ratings with a binwidth of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f87546-c67b-4192-860b-debec22804ce",
   "metadata": {},
   "source": [
    "#### 6. Linear Regression\n",
    "To further clean the data, all rows with na values in either column the IMDB_Rating or Meta_score were removed, then to best determine the relationship between audience perception and meta score of a film a linear regression was performed using Meta_score as the predictor and IMDB_Rating as the response variable. The training data was fit to this workflow to predict parameters for the y-intercept and slope of the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3be12-7e53-4c42-bea5-bf0bdd625eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_training <- na.omit(movies_training)\n",
    "\n",
    "lm_spec <- linear_reg() |>\n",
    "  set_engine(\"lm\") |>\n",
    "  set_mode(\"regression\")\n",
    "\n",
    "# TODO: Swap variables\n",
    "lm_recipe <- recipe(IMDB_Rating ~ Meta_score, data = movies_training)\n",
    "\n",
    "lm_fit <- workflow() |>\n",
    "  add_recipe(lm_recipe) |>\n",
    "  add_model(lm_spec) |>\n",
    "  fit(data = movies_training)\n",
    "lm_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a970f-d553-4d46-a6a3-77ee07e2a8df",
   "metadata": {},
   "source": [
    "#### 7. Visualization of Training Data and Line of Best Fit\n",
    "The linear regression line was then plotted against the training data to visualize its goodness of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec19b0-5e61-4cde-9b2b-dffc3b299fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_preds <- lm_fit |>\n",
    "   predict(movies_training) |>\n",
    "   bind_cols(movies_training)\n",
    "\n",
    "lm_predictions <- movies_preds |>\n",
    "    ggplot(aes(x = Meta_score, y = IMDB_Rating)) +\n",
    "        geom_point(alpha = 0.4) +\n",
    "        geom_line(\n",
    "            mapping = aes(x = Meta_score, y = .pred), \n",
    "            color = \"blue\") +\n",
    "        ggtitle(\"Linear Regression of Meta Score vs. IMDB Rating Score\")+\n",
    "        xlab(\"Meta Score\")+\n",
    "        ylab(\"IMDB Rating\")\n",
    "lm_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656029d-5b43-4262-a744-772ac8d07542",
   "metadata": {},
   "source": [
    "##### Figure 3: \n",
    "Scatter plot of IMDB Rating vs Meta Score for the training data and line of best fit. The IMDB Rating is a value out of 10 representing average user reviews, while the Meta Score is a value out of 100 representing a weighted average of critic scores. The line of best fit in blue was calculated using linear regression fit against the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f228e-6d39-47e9-99f3-50bf5e856195",
   "metadata": {},
   "source": [
    "#### 8. Root Mean Squared Error (RMSE)\n",
    "RMSE was calculated by binding our predicted values to our training data set and calculating metrics with IMDB_Rating as the truth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90b1f2-cdf1-4446-80fa-940d39a83405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_training_results <- lm_fit |>\n",
    "         predict(movies_training) |>\n",
    "         bind_cols(movies_training) |>\n",
    "         metrics(truth = IMDB_Rating, estimate = .pred)\n",
    "\n",
    "lm_rmse <- lm_training_results |>\n",
    "          filter(.metric == \"rmse\") |>\n",
    "          select(.estimate) |>\n",
    "          pull()\n",
    "\n",
    "lm_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a337f-7b52-4a72-9bf7-815a8a3f2f3a",
   "metadata": {},
   "source": [
    "#### 9. Testing\n",
    "The testing data set was then compared to their predictions based on our model and plotted against the line of best fit calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43032b96-8768-4247-9632-7336fcb1e8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_testing <- na.omit(movies_testing)\n",
    "\n",
    "test_preds <-  lm_fit |>\n",
    "   predict(movies_testing) |>\n",
    "   bind_cols(movies_testing)\n",
    "\n",
    "lm_predictions_test <- test_preds |>\n",
    "     ggplot(aes(x = Meta_score, y =IMDB_Rating )) +\n",
    "         geom_point(alpha = 0.4) +\n",
    "         geom_line(\n",
    "             mapping = aes(x = Meta_score, y = .pred), \n",
    "             color = \"blue\") +\n",
    "        xlab(\"Meta Score\")+\n",
    "        ylab(\"IMDB Rating\")+ \n",
    "        ggtitle(\"Meta Score vs IMDB Rating for the Test set\") +\n",
    "         theme(text = element_text(size = 15))\n",
    "\n",
    "lm_predictions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495458a-562b-4367-9d65-5af559a9af23",
   "metadata": {},
   "source": [
    "##### Figure 4: \n",
    "Scatter plot of IMDB Rating vs Meta Score for the testing data and line of best fit. The IMDB Rating is a value out of 10 representing average user reviews, while the Meta Score is a value out of 100 representing a weighted average of critic scores. The line of best fit in blue was calculated using linear regression fit against the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a10967-191d-4810-976f-75d6543eacd1",
   "metadata": {},
   "source": [
    "#### 10. Root Mean Squared Prediction Error (RMSPE)\n",
    "The RMSPE was calculated by using our model to predict IMDB_Rating for our testing data set. This metric is an estimate for our standard deviation of our testing data set against our line of best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef59d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_test_results <- lm_fit |>\n",
    "         predict(movies_testing) |>\n",
    "         bind_cols(movies_testing) |>\n",
    "         metrics(truth = IMDB_Rating, estimate = .pred)\n",
    "\n",
    "lm_rmspe <- lm_test_results |>\n",
    "          filter(.metric == \"rmse\") |>\n",
    "          select(.estimate) |>\n",
    "          pull()\n",
    "\n",
    "lm_rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0788ec-c559-4596-a0d9-08f5d4fe41c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Expected Outcomes and Significance:\n",
    "It was expected that the Meta Scores and IMDb Rating will have a weak positive relationship. Critics are trying to give audiences an accurate expectation on the film based on their ratings so both scoring/rating systems should correlate positively with each other. However, critics and general audiences often look for different things in their ratings, producing more variability between the two ratings, potentially causing a weaker relationship.$^5$ This relationship will allow audiences to understand how a meta score should factor into their decision to see a movie before any general audience ratings are available.\n",
    "\n",
    "Our linear regression produced a standard deviation of about 0.3 against both the training data and testing data (estimate by RMSE and RMSPE respectively). The RMSE and RMSPE are both low considering IMDb ratings are a value out of 10 and IMDb scores average around 7, suggesting a 4% error on average. Considering the errors are similar for both the training and testing data it suggests that our model could be reasonable generalized to a broader set of movies, such as those not in the top 1000 movies on IMDb.\n",
    "\n",
    "It was mentioned that IMDb is great for seeing what general audiences think of a movie. If you don't care what the critics say and want to see what people like yourself thought of a film, then you should use IMDb. We must, however, be aware that fans can skew the vote with 10-star ratings or 1-star ratings, which makes the score vary significantly. Next time you are trying to decide whether a film is worth watching, our linear model can be used to give a representation of potential audience perception given a meta score, but there are other qualitative factors that should also influence your decision to see a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48f1eb9-70a1-4ba5-87ea-19d52f12e8bc",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "\n",
    "1. Shankhdhar, H. (2021, February 1). IMDB movies dataset. Kaggle. https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows \n",
    "\n",
    "2. Türker, B. (2021, August 17). Eda project - what are the factors affecting IMDB ratings?. Medium. https://medium.com/i%CC%87stanbuldatascienceacademy/eda-project-what-are-the-factors-affecting-imdb-ratings-e91f41396c89 \n",
    "\n",
    "3. How do you compute metascores? – metacritic support. Metacritic Support. (2023, October). https://metacritichelp.zendesk.com/hc/en-us/articles/14478499933079-How-do-you-compute-METASCORES- \n",
    "\n",
    "4. Gruber, M. (2022, April 20). How critics produce a film analysis. Ready Steady Cut. https://readysteadycut.com/2022/04/20/how-critics-produce-a-film-analysis/ \n",
    "\n",
    "5. Collazo, M. (2014, April 30). How movie critics and moviegoers view films differently. The Artifice. https://the-artifice.com/movie-critics-and-moviegoers-view-films-differently/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe8ea4-903d-4b28-9b34-e4a0c6c32919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
