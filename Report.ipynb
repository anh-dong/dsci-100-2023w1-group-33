{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ec870a-380e-4d7c-ae81-f7aae633d72a",
   "metadata": {},
   "source": [
    "# Exploring the Relationship Between the Meta Scores of Films and the Reviews of the General Audiance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d90c53-59c7-46f8-ace1-38820a80375f",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "IMDB is an online database for films, television series, podcasts, and other media. This project will be working with movie data from IMDB. The data set of interest contains content data - including cast, production crew, plot summary, and scores. IMDB presents two kinds of scores; IMDB scores which are user-generated averages of reviews submitted to IMDB by the general audience, and Meta Scores which are critic-generated, representing the views of professionals who analyze films.\n",
    "\n",
    "The goal of this project is to answer the following question:\n",
    "\"How accurate are the Meta Scores of films in predicting the reception of the general audience?\"\n",
    "\n",
    "\n",
    "The data set is from Kaggle, and includes data from the top 1000 movies based on the IMDB score. The data set includes the following columns:\n",
    "* Series_Title: the name of the film\n",
    "* Released_year: year it was released\n",
    "* Certificate: certificate earned by the movie\n",
    "* Runtime - total runtime\n",
    "* Genre - list of genres the film falls into\n",
    "* IMDB_Rating - the IMDB rating given by IMDB user reviews\n",
    "* Overview - plot summary\n",
    "* Meta_score - meta score of the movie determined by movie critics\n",
    "* Director - name of the director of the movie\n",
    "* Star1, Star2, Star3, Star4 - names of the stars of the movie in order of significance\n",
    "* No_of_votes - number of reviews on IMDB\n",
    "* Gross - how much money the movie earned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47093674-25bb-4f5d-8c96-d8f59c4e9d25",
   "metadata": {},
   "source": [
    "Dataset Origin: https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5856bb-1f09-47ee-a423-0eae434b800e",
   "metadata": {},
   "source": [
    "## Methods:\n",
    "#### 1. Import Libraries\n",
    "Tidyverse, dplyr, and tidymodels libraries were imported for data manipulation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8653314-ca0b-4c82-82ad-37717519f20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49812b76-0ef9-4609-bb4f-2919110f36d3",
   "metadata": {},
   "source": [
    "#### 2. Read data from repository\n",
    "The data was downloaded from: https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows\n",
    "then added to this project's repository. The following cell reads the data from the repository as a CSV file and filters for films released after 1970, as these films will represent modern conditions better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92eecd-87c5-401a-8934-8651348acf39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Reading from Github\n",
    "url <- \"https://github.com/anh-dong/dsci-100-2023w1-group-33/blob/main/data/imdb_top_1000.csv?raw=true\"\n",
    "movies <- read_csv(url) |>\n",
    "    filter(Released_Year > 1970) |>\n",
    "    select(IMDB_Rating, Meta_score)\n",
    "    # na.omit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee19691-ed5c-4b5b-a64a-80f30a38a847",
   "metadata": {},
   "source": [
    "#### 3. Create Training Data\n",
    "The raw data is then split into a training and testing set of 75% and 25% of the raw data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d2c8c-c110-4d64-a466-0c340f96b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "\n",
    "movies_split <- initial_split(movies, prop = 0.75, strata = Meta_score)\n",
    "movies_training <- training(movies_split)\n",
    "movies_testing <- testing(movies_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf0ce62-f647-4de5-ac4b-d4e0dc3fad79",
   "metadata": {},
   "source": [
    "#### 4. Summary Table\n",
    "The training data was summarized by first normalizing and counting each normalized value for Meta_score and IMDB_Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52bdee0-ad42-43c2-a66b-117f76c46fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_summary <- movies_training |>\n",
    "    mutate(Meta_score = round(scale(Meta_score), 0), IMDB_Rating = round(scale(IMDB_Rating), 0))\n",
    "\n",
    "movies_table_Meta_scores <- movies_summary |>\n",
    "    group_by(Meta_score) |>\n",
    "    summarize(Meta_score_count = n()) |>\n",
    "    rename(normalized_value = Meta_score)\n",
    "\n",
    "movies_table_IMDB_Rating <- movies_summary |>\n",
    "    group_by(IMDB_Rating) |>\n",
    "    summarize(IMDB_Rating_count = n()) |>\n",
    "    rename(normalized_value = IMDB_Rating)\n",
    "\n",
    "joined <- left_join(movies_table_Meta_scores, movies_table_IMDB_Rating) |>\n",
    "    mutate(IMDB_Rating_count = replace(IMDB_Rating_count, is.na(IMDB_Rating_count), 0))\n",
    "joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca8e8b-41c9-47fe-b613-9c639a69b03a",
   "metadata": {},
   "source": [
    "##### Table 1:\n",
    "Counts of normalized values for Meta_score and IMDB_Rating for the training data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f1f57-87e7-4ef7-90f0-e53c4517928c",
   "metadata": {},
   "source": [
    "#### 5. Summary Visual\n",
    "The distribution of the normalized data was then visualized by plotting them on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c2905-0ef5-4bdf-8b06-c3e0b725be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta_score_hist <- movies_summary |>\n",
    "    ggplot(aes(Meta_score)) +\n",
    "        geom_histogram(binwidth = 1) +\n",
    "        xlab(\"Normalized Meta Score\") +\n",
    "        ylab(\"Count\") +\n",
    "        ggtitle(\"Distribution of Normalized Meta Scores\")\n",
    "Meta_score_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa6e19-d18f-4721-8270-68ee4e28383f",
   "metadata": {},
   "source": [
    "##### Figure 1:\n",
    "Histogram of normalized IMDB Ratings using geom_histogram with a binwidth of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc5cd3-d9e6-4f91-b391-7a98d1d7c59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMDB_Review_hist <- movies_summary |>\n",
    "    ggplot(aes(IMDB_Rating)) +\n",
    "        geom_histogram(binwidth = 1) +\n",
    "        xlab(\"Normalized IMDB Rating\") +\n",
    "        ylab(\"Count\") +\n",
    "        ggtitle(\"Distribution of Normalized IMDB Ratings\") +\n",
    "        \n",
    "IMDB_Review_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0a5e9-62df-4f5f-92b1-1e29416b83f4",
   "metadata": {},
   "source": [
    "##### Figure 2: \n",
    "Histogram of normalized IMDB Ratings with a binwidth of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f87546-c67b-4192-860b-debec22804ce",
   "metadata": {},
   "source": [
    "#### 6. Linear Regression\n",
    "To best determine the relationship between the IMDB Rating and the Meta Score a linear regression was performed using Meta_score as the predictor and IMDB Rating as the response variable. The training data was fit to this workflow to predict parameters for the y-intercept and slope of the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3be12-7e53-4c42-bea5-bf0bdd625eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_spec <- linear_reg() |>\n",
    "  set_engine(\"lm\") |>\n",
    "  set_mode(\"regression\")\n",
    "\n",
    "lm_recipe <- recipe(IMDB_Rating ~ Meta_score, data = movies_training)\n",
    "\n",
    "lm_fit <- workflow() |>\n",
    "  add_recipe(lm_recipe) |>\n",
    "  add_model(lm_spec) |>\n",
    "  fit(data = movies_training)\n",
    "lm_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a970f-d553-4d46-a6a3-77ee07e2a8df",
   "metadata": {},
   "source": [
    "#### 7. Visualization of Training Data and Line of Best Fit\n",
    "The linear regression line was then plotted against the training data to visualize how well it fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec19b0-5e61-4cde-9b2b-dffc3b299fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_preds <- lm_fit |>\n",
    "   predict(movies_training) |>\n",
    "   bind_cols(movies_training)\n",
    "\n",
    "lm_predictions <- movies_preds |>\n",
    "    ggplot(aes(x = Meta_score, y = IMDB_Rating)) +\n",
    "        geom_point(alpha = 0.4) +\n",
    "        geom_line(\n",
    "            mapping = aes(x = Meta_score, y = .pred), \n",
    "            color = \"blue\") +\n",
    "        ggtitle(\"Linear Regression of Meta Score vs. IMDB Rating Score\")+\n",
    "        xlab(\"Meta Score\")+\n",
    "        ylab(\"IMDB Rating\")\n",
    "lm_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656029d-5b43-4262-a744-772ac8d07542",
   "metadata": {},
   "source": [
    "##### Figure 3: \n",
    "Scatter plot of IMDB Rating vs Meta Score. The IMDB Rating is a value out of 10 representing user reviews, while the Meta Score is a value out of 100 representing critic scores. The line of best fit in blue was calculated using linear regression fit against the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f228e-6d39-47e9-99f3-50bf5e856195",
   "metadata": {},
   "source": [
    "#### 8. Root Mean Squared Error (RMSE)\n",
    "RMSE was calculated by binding our predicted values to our training data set and calculating metrics with IMDB_Rating as out truth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e779458-66a2-4512-ab0f-f88a8bfd22d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_training_results <- lm_fit |>\n",
    "         predict(movies_training) |>\n",
    "         bind_cols(movies_training) |>\n",
    "         metrics(truth = IMDB_Rating, estimate = .pred)\n",
    "\n",
    "lm_rmse <- lm_training_results |>\n",
    "          filter(.metric == \"rmse\") |>\n",
    "          select(.estimate) |>\n",
    "          pull()\n",
    "\n",
    "lm_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a337f-7b52-4a72-9bf7-815a8a3f2f3a",
   "metadata": {},
   "source": [
    "#### 9. Testing\n",
    "The testing data set was then compared to their predictions based on our model and plotted against the line of best fit calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43032b96-8768-4247-9632-7336fcb1e8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds <-  lm_fit |>\n",
    "   predict(movies_testing) |>\n",
    "   bind_cols(movies_testing)\n",
    "\n",
    "lm_predictions_test <- test_preds |>\n",
    "     ggplot(aes(x = Meta_score, y =IMDB_Rating )) +\n",
    "         geom_point(alpha = 0.4) +\n",
    "         geom_line(\n",
    "             mapping = aes(x = Meta_score, y = .pred), \n",
    "             color = \"blue\") +\n",
    "        xlab(\"Meta Score\")+\n",
    "        ylab(\"IMDB Rating\")+ \n",
    "        ggtitle(\"Meta Score vs IMDB Rating for the Test set\") +\n",
    "         theme(text = element_text(size = 15))\n",
    "\n",
    "lm_predictions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495458a-562b-4367-9d65-5af559a9af23",
   "metadata": {},
   "source": [
    "##### Figure 4: \n",
    "The training data set is plotted with IMDB Rating against Meta Score. IMDB Rating are from reviews of a general audience as a score out of 10. The Meta Score is an aggregate critic score out of 100. The blue line was determined through a linear regression of our training data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a10967-191d-4810-976f-75d6543eacd1",
   "metadata": {},
   "source": [
    "#### 10. Root Mean Sqaured Precent Error (RMSPE)\n",
    "The RMSPE was calculated by using our model to predict IMDB_Rating for our testing data set. This metric is an an estimate for our standard deviation of our testing data set against our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef59d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_test_results <- lm_fit |>\n",
    "         predict(movies_testing) |>\n",
    "         bind_cols(movies_testing) |>\n",
    "         metrics(truth = IMDB_Rating, estimate = .pred)\n",
    "\n",
    "lm_rmspe <- lm_test_results |>\n",
    "          filter(.metric == \"rmse\") |>\n",
    "          select(.estimate) |>\n",
    "          pull()\n",
    "\n",
    "lm_rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0788ec-c559-4596-a0d9-08f5d4fe41c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Expected Outcomes and Significance:\n",
    "It is expected that the Meta Scores and audience reception will have a weak positive relationship. Critics are trying to give audiences an accurate expectation on the film based on their ratings so they should correlate positively with each other. However, critics and general audiences often look for different things in their ratings, producing more variability between the two ratings, potentially causing a weaker relationship. This relationship will allow audiences to understand how a meta score should factor into their decision to see a movie before any general audience ratings are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f92c2b-b924-440e-a6d8-44376ff86d79",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Resources:\n",
    "\n",
    "How Meta Scores are computed:\n",
    "\n",
    "How do you compute metascores? – metacritic support. Metacritic Support. (2023, October). https://metacritichelp.zendesk.com/hc/en-us/articles/14478499933079-How-do-you-compute-METASCORES- \n",
    "\n",
    "\n",
    "\n",
    "Factors that influence Meta Scores (critics): \n",
    "\n",
    "Gruber, M. (2022, April 20). How critics produce a film analysis. Ready Steady Cut. https://readysteadycut.com/2022/04/20/how-critics-produce-a-film-analysis/ \n",
    "\n",
    "\n",
    "\n",
    "Factors that effect IMDB score (a report): \n",
    "\n",
    "Türker, B. (2021, August 17). Eda project - what are the factors affecting IMDB ratings?. Medium. https://medium.com/i%CC%87stanbuldatascienceacademy/eda-project-what-are-the-factors-affecting-imdb-ratings-e91f41396c89 \n",
    "\n",
    "\n",
    "\n",
    "Inconsistency in how movie critics and general viewers judge films:\n",
    "\n",
    "Collazo, M. (2014, April 30). How movie critics and moviegoers view films differently. The Artifice. https://the-artifice.com/movie-critics-and-moviegoers-view-films-differently/ \n",
    "\n",
    "\n",
    "Data Set Origin:\n",
    "\n",
    "Shankhdhar, H. (2021, February 1). IMDB movies dataset. Kaggle. https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
