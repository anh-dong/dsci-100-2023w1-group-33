{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ec870a-380e-4d7c-ae81-f7aae633d72a",
   "metadata": {},
   "source": [
    "# Exploring the Relationship Between the Meta Scores of Films and the Reviews of the General Audiance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d90c53-59c7-46f8-ace1-38820a80375f",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "IMDB is an online database for films, television series, podcasts, and other media. This project will be working with movie data from IMDB. The data set of interest contains content data - including cast, production crew, plot summary, and scores. IMDB presents two kinds of scores; IMDB scores which are user-generated averages of reviews submitted to IMDB by the general audience, and Meta Scores which are critic-generated, representing the views of professionals who analyze films.\n",
    "\n",
    "The goal of this project is to answer the following question:\n",
    "\"How accurate are the Meta Scores of films in predicting the reception of the general audience?\"\n",
    "\n",
    "\n",
    "The data set is from Kaggle, and includes data from the top 1000 movies based on the IMDB score. The data set includes the following columns:\n",
    "* Series_Title: the name of the film\n",
    "* Released_year: year it was released\n",
    "* Certificate: certificate earned by the movie\n",
    "* Runtime - total runtime\n",
    "* Genre - list of genres the film falls into\n",
    "* IMDB_Rating - the IMDB rating given by IMDB user reviews\n",
    "* Overview - plot summary\n",
    "* Meta_score - meta score of the movie determined by movie critics\n",
    "* Director - name of the director of the movie\n",
    "* Star1, Star2, Star3, Star4 - names of the stars of the movie in order of significance\n",
    "* No_of_votes - number of reviews on IMDB\n",
    "* Gross - how much money the movie earned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47093674-25bb-4f5d-8c96-d8f59c4e9d25",
   "metadata": {},
   "source": [
    "Dataset Origin: https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f9d757-0eb8-4557-93b8-e9e9866962b8",
   "metadata": {},
   "source": [
    "## Methods:\n",
    "The data will first be prepared by filtering for films released after 1970 and removing films without values in the Meta_score column. The relationship will be determined with a training data set containing 75% of the films a k-nn regression model using Meta_scores as the predictive variable and IMDB_Rating as the response variable. The k value will be determined through a tuning process to produce the minimal error between the training data set and the testing data set containing the films not found in the training data set. The error in the regression produced will give an indication on how strong the relationship is between the two variables. \n",
    "\n",
    "To visualize the result the scatter plot will be overlaid with a line produced by the regression to show whether the data is positively or negatively correlated and how much spread there is from the line and the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5856bb-1f09-47ee-a423-0eae434b800e",
   "metadata": {},
   "source": [
    "Tidyverse, dplyr, and tidymodels libraries were imported for data manipulation and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8653314-ca0b-4c82-82ad-37717519f20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Initialize libraries. \n",
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49812b76-0ef9-4609-bb4f-2919110f36d3",
   "metadata": {},
   "source": [
    "The data was downloaded from: https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows\n",
    "then added to this project's repository. The following cell reads the data from the repository as a CSV file and filters for films released after 1970, as these films will represent modern conditions better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92eecd-87c5-401a-8934-8651348acf39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Reading from Github\n",
    "url <- \"https://github.com/anh-dong/dsci-100-2023w1-group-33/blob/main/data/imdb_top_1000.csv?raw=true\"\n",
    "movies <- read_csv(url) |>\n",
    "    filter(Released_Year > 1970) |>\n",
    "    select(IMDB_Rating, Meta_score) |>\n",
    "    na.omit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee19691-ed5c-4b5b-a64a-80f30a38a847",
   "metadata": {},
   "source": [
    "The raw data is then split into a training and testing set of 75% and 25% of the raw data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d2c8c-c110-4d64-a466-0c340f96b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training data\n",
    "set.seed(1234)\n",
    "\n",
    "movies_split <- initial_split(movies, prop = 0.75, strata = Meta_score)\n",
    "movies_training <- training(movies_split)\n",
    "movies_testing <- testing(movies_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf0ce62-f647-4de5-ac4b-d4e0dc3fad79",
   "metadata": {},
   "source": [
    "A plot of IMDB_Rating vs Meta_score was created using ggplot and geom_point. Since there was significant overlap between many data points, an alpha of ___ was used to visualize all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e05696-d425-42d5-a3ff-795af12436fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.height = 8, repr.plot.width = 7)\n",
    "# your code here\n",
    "movies_eda <- movies_training |>\n",
    "    ggplot(aes(x = Meta_score, y = IMDB_Rating)) +\n",
    "        geom_point(alpha = 0.2) +\n",
    "        xlab(\"Meta Sc\n",
    "ore\") +\n",
    "        ylab(\"IMDB Rating\") +\n",
    "        ggtitle(\"IMDB Rating vs Meta Score\")\n",
    "movies_eda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f87546-c67b-4192-860b-debec22804ce",
   "metadata": {},
   "source": [
    "To best determine the relationship between the IMDB Rating and the Meta Score a linear regression was performed using Meta_score as the predictor and IMDB Rating as the response variable. The training data was fit to this workflow to predict parameters for the y-intercept and slope of the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3be12-7e53-4c42-bea5-bf0bdd625eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_spec <- linear_reg() |>\n",
    "  set_engine(\"lm\") |>\n",
    "  set_mode(\"regression\")\n",
    "\n",
    "# TODO: Swap variables\n",
    "lm_recipe <- recipe(IMDB_Rating ~ Meta_score, data = movies_training)\n",
    "\n",
    "lm_fit <- workflow() |>\n",
    "  add_recipe(lm_recipe) |>\n",
    "  add_model(lm_spec) |>\n",
    "  fit(data = movies_training)\n",
    "lm_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a970f-d553-4d46-a6a3-77ee07e2a8df",
   "metadata": {},
   "source": [
    "The linear regression line was then plotted against the training data to visualize how well it fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec19b0-5e61-4cde-9b2b-dffc3b299fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_preds <- lm_fit |>\n",
    "   predict(movies_training) |>\n",
    "   bind_cols(movies_training)\n",
    "\n",
    "lm_predictions <- movies_preds |>\n",
    "    ggplot(aes(x = Meta_score, y = IMDB_Rating)) +\n",
    "        geom_point(alpha = 0.4) +\n",
    "        geom_line(\n",
    "            mapping = aes(x = Meta_score, y = .pred), \n",
    "            color = \"blue\") +\n",
    "        ggtitle(\"Linear Regression of Meta Score vs. IMDB Rating Score\")+\n",
    "        xlab(\"Meta Score\")+\n",
    "        ylab(\"IMDB Rating Score\")+\n",
    "        theme(text = element_text(size = 20))\n",
    "lm_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656029d-5b43-4262-a744-772ac8d07542",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e779458-66a2-4512-ab0f-f88a8bfd22d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: We should calculate this, it will help us determine how good our prediction is.\n",
    "lm_test_results <- lm_fit |>\n",
    "         predict(movies_testing) |>\n",
    "         bind_cols(movies_testing) |>\n",
    "         metrics(truth = Meta_score, estimate = .pred)\n",
    "\n",
    "lm_rmspe <- lm_test_results |>\n",
    "          filter(.metric == \"rmse\") |>\n",
    "          select(.estimate) |>\n",
    "          pull()\n",
    "\n",
    "\n",
    "lm_rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90b1f2-cdf1-4446-80fa-940d39a83405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_training_results <- lm_fit |>\n",
    "         predict(movies_training) |>\n",
    "         bind_cols(movies_training) |>\n",
    "         metrics(truth = Meta_score, estimate = .pred)\n",
    "\n",
    "lm_rmse <- lm_training_results |>\n",
    "          filter(.metric == \"rmse\") |>\n",
    "          select(.estimate) |>\n",
    "          pull()\n",
    "\n",
    "lm_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a337f-7b52-4a72-9bf7-815a8a3f2f3a",
   "metadata": {},
   "source": [
    "The testing data set was then compared to their predictions based on our model and plotted against the line of best fit calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43032b96-8768-4247-9632-7336fcb1e8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds <-  lm_fit |>\n",
    "   predict(movies_testing) |>\n",
    "   bind_cols(movies_testing)\n",
    "\n",
    "lm_predictions_test <- test_preds |>\n",
    "     ggplot(aes(x = Meta_score, y =IMDB_Rating )) +\n",
    "         geom_point(alpha = 0.4) +\n",
    "         geom_line(\n",
    "             mapping = aes(x = Meta_score, y = .pred), \n",
    "             color = \"blue\") +\n",
    "xlab(\"Meta Score\")+\n",
    "ylab(\"IMDB Rating Score\")+\n",
    "         theme(text = element_text(size = 20))\n",
    "lm_predictions_test\n",
    "#TODO: in general we should try and get rid of the warning messages. I think this should be done when we remove NA values from our training/testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0788ec-c559-4596-a0d9-08f5d4fe41c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Expected Outcomes and Significance:\n",
    "It is expected that the Meta Scores and audience reception will have a weak positive relationship. Critics are trying to give audiences an accurate expectation on the film based on their ratings so they should correlate positively with each other. However, critics and general audiences often look for different things in their ratings, producing more variability between the two ratings, potentially causing a weaker relationship. This relationship will allow audiences to understand how a meta score should factor into their decision to see a movie before any general audience ratings are available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
